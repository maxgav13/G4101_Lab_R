---
title: "Lab 9: Estadistica Inferencial - No Parametrica"
author: "Maximiliano Garnier Villarreal"
lang: es
toc: true
toc-depth: 3
toc-title: Contenidos
number-sections: true
highlight-style: pygments
theme: sandstone
format:
  html:
    code-fold: true
    code-summary: "Codigo"
    code-tools: true
    html-math-method: katex
  pdf: default
  docx: default
execute:
  warning: false
  error: false
  echo: true
---

# Paquetes

```{r}
#| label: setup
#| include: false

library(rio)            # importar datos
library(vroom)          # importar datos
library(MOTE)           # tamanho del efecto
library(papaja)         # presentacion datos
library(DescTools)      # pruebas
library(rstatix)        # pruebas y tamanho efecto
library(ggstatsplot)    # graficos de pruebas
library(broom)          # resumenes tidy modelos
library(rsample)        # remuestreo
library(tidyverse)
library(easystats)

options(digits = 3)

theme_set(theme_minimal(base_size = 14))

signed_rank = function(x) sign(x) * rank(abs(x))
```

> Para las pruebas no parametricas se trabaja con los datos **ranqueados**

# Correlacion de Spearman

$$H_0 : \rho_s = 0$$

```{r}
a = c(8,16,12,13,16,14,16,11,15,13)
b = c(7,8,10,12,14,9,13,6,9,10)
c = c(3,5,9,5,5,8,13,3,9,9)
alfa = .1

cordat = tibble(a,b,c)

cordat %>% 
  mutate(across(where(is.numeric),
                list(r=rank),
                .names = '{.col}_{.fn}'),
         dr = (a_r - b_r)^2) %>% 
  summarise(n = n(),
            sr = sum(dr),
            r = 1 - ((6*sr)/(n*((n^2)-1))),
            r.low = CorCI(r,n,conf.level = 1-alfa)[2],
            r.high = CorCI(r,n,conf.level = 1-alfa)[3])

cor.test(a,b, method = "spearman", conf = 1-alfa) %>% 
  tidy()

SpearmanRho(a,b, conf.level = 1-alfa) # DescTools

cor.test(rank(a),rank(b), conf = 1-alfa) %>% 
  tidy()

correlation::cor_test(cordat,'a','b',
                      method = 'spearman',
                      ci = 1-alfa) %>% 
  tibble()
```

## Grafico resumen

```{r}
ggscatterstats(cordat, a, b,
               marginal = F,
               type = 'np',
               conf.level = 1-alfa,
               bf.message = F)
```

# Prueba de Kolmogorov-Smirnov

```{r}
# Ho: muestras tienen igual forma, o, muestra sigue forma propuesta
set.seed(4101)
x = rnorm(100, 1, 3)
y = rnorm(100, 2, 10)
ks.test(x, y) %>% tidy()
ks.test(x, 'pnorm', 1, 3) %>% 
  tidy()
ks.test(y, 'pnorm', 2, 10) %>% 
  tidy()
dat <- tibble(x = c(x, y), g = rep(c('1','2'), each = 100))
ggplot(dat, aes(x, colour = g)) + 
  stat_ecdf(linewidth=1) +
  theme(legend.position = 'inside',
        legend.position.inside = c(.8,.3)) +
  labs(col='Muestra')
```

# Prueba de rango con signo de Wilcoxon

$$H_0 : \text{mediana muestra} = \text{mediana hipotetica}$$

```{r}
verm = c(6.1, 5.5, 5.3, 6.8, 7.6, 5.3, 6.9, 6.1, 5.7)
alfa = .05
mu = 7

verm %>% 
  enframe() %>% 
  mutate(diff = value-mu) %>% 
  filter(diff != 0) %>% 
  mutate(signo = sign(diff), 
         ranking = rank(abs(diff)),
         signo = factor(signo,
                        levels = c(-1,1),
                        labels = c('Negativo','Positivo'))) %>% 
  group_by(signo) %>% 
  summarise(w = sum(ranking))
```

## Prueba

```{r}
wilcox.test(x = verm, mu=7, 
            conf.int = T, conf.level = 1-alfa) %>% 
  tidy()
```

## Tamanho del efecto

$$
r = \frac{|Z|}{\sqrt{N}}
$$

$$
r_b = \frac{2 \cdot(w_+ - w_-)}{N \cdot (N+1)}
$$

$$
cles \ (PS) = \frac{2 \cdot w_{max}}{N \cdot (N+1)} 
$$

### Correlacion ($r$)

```{r}
# rstatix
set.seed(101)
wilcox_effsize(enframe(verm), value~1, mu = 7,
               ci = T, conf.level = 1-alfa)
```

### Correlacion de rango biserial ($r_b$)

```{r}
# effectsize
rank_biserial(verm, mu = 7, ci = 1-alfa)
```

### Tamanho de efecto en lenguaje comun (CLES)

```{r}
# effectsize
rb_to_p_superiority(.87)
```

## Grafico resumen

```{r}
gghistostats(enframe(verm), value,
             test.value = 7,
             type = 'np',
             conf.level = 1-alfa,
             bf.message = F)
```

# Prueba de suma de rangos de Wilcoxon o Prueba-U de Mann-Whitney

$$H_0 : \bar{R}_1 = \bar{R}_2$$

```{r}
A = c(25, 40, 34, 37, 38, 35, 29, 32, 35, 44, 27, 33, 37, 38, 36)
B = c(45, 37, 36, 38, 49, 47, 32, 41, 38, 45, 33, 39, 46, 47, 40)
alfa = .05

mol = stack(list(A=A,B=B)) %>% 
  as_tibble()

mol %>% 
  mutate(ranking = rank(values)) %>% 
  group_by(ind) %>% 
  summarise(n = n(), 
            valor_medio = mean(values),
            valor_mediana = median(values),
            rango_medio = mean(ranking), 
            w = sum(ranking)) %>% 
  mutate(u = w - (n*(n+1))/2)
```

## Prueba

```{r}
wilcox.test(values ~ ind, data = mol, 
            conf.int = T, conf.level = 1-alfa) %>% 
  tidy()
```

## Tamanho del efecto

$$
r = \frac{|Z|}{\sqrt{N}}
$$

$$
r_b = \frac{2 \cdot (\bar{R}_1-\bar{R}_2)}{N}
$$

$$
\delta = \frac{2 \cdot U}{n_1n_2}-1 
$$

$$
cles \ (PS) = \frac{U_{max}}{n_1n_2} 
$$

### Correlacion ($r$)

```{r}
# rstatix
set.seed(101)
wilcox_effsize(mol, values ~ ind,
               ci = T, conf.level = 1-alfa)
```

### Correlacion de rango biserial ($r_b$)

```{r}
# effectsize
rank_biserial(values ~ ind, data = mol, ci = 1-alfa)
```

### Delta de Cliff ($\delta$)

```{r}
# effectsize
cliffs_delta(values ~ ind, data = mol, ci = 1-alfa)
```

### Tamanho de efecto en lenguaje comun (CLES)

```{r}
# effectsize
rb_to_p_superiority(.61)
```

## Grafico resumen

```{r}
ggbetweenstats(mol, ind, values,
               type = 'np',
               conf.level = 1-alfa,
               bf.message = F)
```

# Prueba de Kruskal-Wallis

$$H_0 : \bar{R}_1 = \bar{R}_2 = \bar{R}_3 = \dotsb = \bar{R}_n$$

```{r}
dat1 = vroom('data/anova MgO.csv')

G1 = c(7,8,10,11) # Mt Mica
G2 = c(4,5,7,8) # Sebago Bath
G3 = c(1,2,4,5) # Black Mt
alfa = .05

Stacked = stack(list(G1=G1,G2=G2,G3=G3)) %>% 
  as_tibble()

Stacked %>% 
  mutate(ranking = rank(values)) %>% 
  group_by(ind) %>% 
  summarise(n = n(), 
            valor_medio = mean(values),
            valor_mediana = median(values),
            rango_medio = mean(ranking), 
            w = sum(ranking))
```

## Prueba

```{r}
kruskal.test(values ~ ind, data = Stacked) %>% 
  tidy()
```

## Tamanho del efecto

### Epsilon-cuadrado ($\epsilon_{ord}^2$)

$$
\epsilon_{ord}^2 = \frac{H}{(N^2-1)/(N+1)}
$$

```{r}
(7.65) / ((12^2 - 1)/(12 + 1))
```

```{r}
# effectsize
rank_epsilon_squared(values ~ ind, data = Stacked, 
                     ci = 1-alfa, alternative = 'two')
```

### Eta-cuadrado ($\eta_H^2$)

$$
\eta_H^2 = \frac{H - k + 1}{N - k}
$$

```{r}
(7.65 - 3 + 1) / (12 - 3)
```

```{r}
# rstatix
set.seed(101)
kruskal_effsize(Stacked, values ~ ind,
                ci = T, conf.level = 1-alfa)
```

## Analisis Post-hoc

```{r}
DunnTest(values~ind, Stacked, method = 'holm') # DescTools
```

```{r}
KW.post = dunn_test(Stacked, values ~ ind, 
                    p.adjust.method = 'holm',detailed = T) %>% 
  mutate(r = map2_dbl(.x = group1, .y = group2,
                      ~wilcox_effsize(values ~ ind, 
                                      data = Stacked %>% 
                                        filter(ind %in% c(.x,.y)) %>% 
                                        mutate(ind = fct_drop(ind))) %>% 
                        pull(effsize)),
         r.low = map2_dbl(.x = r, .y = (n1 + n2),
                          ~CorCI(.x, n = .y, conf.level = 1-alfa)[2]),
         r.high = map2_dbl(.x = r, .y = (n1 + n2),
                           ~CorCI(.x, n = .y, conf.level = 1-alfa)[3])) %>% 
  relocate(starts_with('r'),.after = estimate)
KW.post
```

## Grafico resumen

```{r}
ggbetweenstats(Stacked, ind, values,
               type = 'np',
               conf.level = 1-alfa,
               p.adjust.method = "holm",
               pairwise.display = 's', # s, ns, all
               bf.message = F)
```

# Bootstrap con *rsample*

Remuestreo con remplazamiento, a cada una de la muestras se le calcula el estadistico o dato de interes. El intervalo de confianza es a partir de cuantiles, por lo general 2.5% y 97.5% para un $1 - \alpha = 95 \%$

## Media ($\bar{x}$)

```{r}
mu = 7
alfa = .05
n = length(verm)

set.seed(4101)
m = bootstraps(data = tibble(verm), times = 1000)

avg = function(split) {
  split %>% 
    analysis() %>% 
    pull(1) %>% 
    mean()
}

d = function(split) {
  vec = split %>% 
    analysis() %>% 
    pull(1)  
  d = (mean(vec) - mu) / sd(vec)
  return(d)
}

# avg2 = as_mapper(~ .x %>% analysis %>% pull(1) %>% mean)
# avg3 = compose(mean, partial(pull, var=1), analysis)

m = m %>% 
  mutate(avg = map_dbl(splits, ~avg(.)),
         d = map_dbl(splits, ~d(.)),
         )
```

```{r}
m.s = m %>% 
  summarise(across(where(is.numeric),
                   list(media = ~mean(.x),
                        sd = ~sd(.x),
                        q1 = ~quantile(.x,alfa/2),
                        q2 = ~quantile(.x,.5),
                        q3 = ~quantile(.x,1-alfa/2)),
                   .names = '{.col}_{.fn}'))

m.s %>% 
  pivot_longer(cols = everything(),
               names_to = c('param','stat'),
               names_sep = '_',
               values_to = 'value') %>% 
  arrange(param)

myvar = 'avg' # variable a graficar: avg, d

ggplot(m, aes(get(myvar))) +
  geom_histogram(bins = 20, col = 'black', fill = 'grey80') +
  geom_vline(xintercept = unlist(m.s %>% select(starts_with(str_glue('{myvar}_q')))), 
             col = c('blue','red','blue')) +
  labs(x = myvar)

```

## $R^2$

```{r}
set.seed(4101)

alfa = .05

R2 = bootstraps(data = mol, times = 1000, strata = 'ind')

r2 = function(split) {
  split %>% 
    analysis() %>% 
    lm(values ~ ind, data = .) %>% 
    glance() %>% 
    pull(r.squared)
}

R2 = R2 %>% 
  mutate(r2 = map_dbl(splits, ~r2(.)))
```

```{r}
R2.s = R2 %>% 
  summarise(across(where(is.numeric),
                   list(media = ~mean(.x),
                        q1 = ~quantile(.,alfa/2),
                        q2 = ~quantile(.,.5),
                        q3 = ~quantile(.,1-alfa/2)),
                   .names = '{.col}_{.fn}'))
R2.s

ggplot(R2, aes(r2)) +
  geom_histogram(bins = 20, col = 'black', fill = 'grey80') +
  geom_vline(xintercept = R2.s[-1] %>% unlist(), 
             col = c('blue','red','blue'))
```

## $\eta^2$

```{r}
set.seed(4101)
alfa = .05
eta2 = bootstraps(data = Stacked, times = 1000, strata = 'ind')

eta = function(split) {
  dat = split %>% 
    analysis() 
  H = kruskal.test(values ~ ind, data=dat) %>% 
    tidy() %>% 
    pull(statistic)
  N = nrow(dat)
  k = nlevels(dat$ind)
  eta = (H - k + 1) / (N - k)
  return(eta)
}

eta2 = eta2 %>% 
  mutate(eta2 = map_dbl(splits, ~eta(.)))
```

```{r}
eta2.s = eta2 %>% 
  summarise(across(where(is.numeric),
                   list(media = ~mean(.x),
                        q1 = ~quantile(.,alfa/2),
                        q2 = ~quantile(.,.5),
                        q3 = ~quantile(.,1-alfa/2)),
                   .names = '{.col}_{.fn}'))
eta2.s

ggplot(eta2, aes(eta2)) +
  geom_histogram(bins = 20, col = 'black', fill = 'grey80') +
  geom_vline(xintercept = eta2.s[-1] %>% unlist(), 
             col = c('blue','red','blue'))
```
