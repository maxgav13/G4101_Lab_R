---
title: "Lab 12: Geoestadistica"
author: "Maximiliano Garnier Villarreal"
lang: es
toc: true
toc-depth: 3
toc-title: Contenidos
number-sections: true
highlight-style: pygments
theme: sandstone
format:
  html:
    embed-resources: true
    code-fold: true
    code-summary: "Codigo"
    code-tools: true
    html-math-method: katex
  pdf: 
    prefer-html: false
  docx: default
execute:
  warning: false
  error: false
  echo: true
---

# Paquetes

```{r}
#| label: setup
#| include: false

library(MOTE)
library(papaja)
library(spatialsample)  # validacion cruzada espacial
library(gstat)          # geoestadistica
# library(sp)             # objetos espaciales vectoriales
library(sf)             # objetos espaciales vectoriales
library(plotly)         # graficos interactivos
# library(raster)         # objetos espaciales raster
# library(terra)         # objetos espaciales raster
library(stars)          # arreglos de objetos espaciales
library(tmap)
library(viridis)        # colores
library(DescTools)      # analisis de datos
# library(mapview)        # mapas interactivos
library(RColorBrewer)   # colores
library(ggrepel)        # etiquetas en ggplot2
library(tidyverse)

# Opciones para ggplot
theme_set(theme_minimal(base_size = 14))
theme_update(legend.position='right')
x_var = 'Distancia [m]'
y_var = 'Semivarianza'
x_map = 'X [m]'
y_map = 'Y [m]'
x_vmap = "Distancia E-W [m]"
y_vmap = "Distancia N-S [m]"
```

# Datos

## Importar datos

```{r datos}
datos <- rio::import("data/BroomsBarn3.csv", setclass = 'tibble')
datos %>% glimpse()
```

## Exploracion de datos

Importante realizar este paso para determinar si la variable esta normalmente distribuida o no; de no estarlo habria que transformarla.

```{r AED}
myvar0 = 'K' # variable a modelar

Desc(datos[[myvar0]], plotit = F)

(S = var(datos[[myvar0]])) # varianza de la variable

ggplot(datos, aes(.data[[myvar0]])) + 
  geom_histogram(aes(y = after_stat(density)), bins = 10, 
                 col = 'black', fill = 'blue', alpha = .5) + 
  geom_vline(xintercept = mean(datos[[myvar0]]), col = 'red') +
  geom_density(col = 'blue') +
  labs(y = 'Densidad')
```

```{r}
transformar = T

if (isFALSE(transformar)) {
  myvar = myvar0 
} else {
  myvar = str_glue('{myvar0}.trans') 
}
```

## Transformacion de datos

::: callout-note
Si se ocupa transformar la variable y si se quiere obtener el resultado en la escala original de la variable, esto solo se puede lograr por medio de Kriging Ordinario ($y \sim 1$), no aplica para cualquier otro tipo de Kriging. La teoría y funciones aqui implementadas, para re-transformar el resultado de la interpolacion, solo se han desarrollado para esta variante del Kriging.
:::

Una opcion es la normalizacion/estandarizacion de la variable a una con media de 0 y desviación estándar de 1, esto se logra utilizando la transformacion de cuantiles (`qqnorm`).

```{r}
if (isTRUE(transformar)) {
  var.z = qqnorm(datos[[myvar0]], plot.it = F)$x
  }
```

Otra opcion es transformacion de Box-Cox donde se debe hallar el parametro $\lambda$ para transformar la variable lo mas cercano a una variable normalmente distribuida. La transformacion logaritmica (natural, base $e$) es un caso especial donde $\lambda=0$.

$$
\begin{cases}
  \frac{x^\lambda-1}{\lambda} & \text{para } \lambda \neq 0\\
  log(x) & \text{para } \lambda = 0
  \end{cases}
$$

La siguiente tabla muestra los valores mas tipicos de $\lambda$ con su respectiva transformacion, donde tipicamente se usan valores entre -2 y 2, pero puede ir desde -5 a 5.

| $\lambda$ | Transformacion |
|:---------:|:--------------:|
|    -2     |    $1/x^2$     |
|    -1     |     $1/x$      |
|   -0.5    |  $1/\sqrt{x}$  |
|     0     |    $log(x)$    |
|    0.5    |   $\sqrt{x}$   |
|     1     |      $x$       |
|     2     |     $x^2$      |

```{r box-cox}
if (isTRUE(transformar)) {
  bc = MASS::boxcox(datos[[myvar0]] ~ 1)
  bc.lambda = bc$x[which.max(bc$y)]
  # (bc.lambda = bc %>% as_tibble() %>% slice_max(y,n = 1) %>% pull(x))
  var.bc = BoxCox(datos[[myvar0]], bc.lambda)
  str_glue('El lambda para {myvar0} es {apa(bc.lambda,3)}')
}
lambda = bc.lambda
```

La funcion `MASS::boxcox` realiza la busqueda de $\lambda$ y muestra un grafico donde la linea punteada central es el valor optimo y las otras lineas punteadas representan el IC al 95%.

```{r}
if (isTRUE(transformar)) {

  transformacion = "Quantile"  # "Box-Cox" o "Quantile"
  
  if (transformacion == "Box-Cox") {
    datos = datos %>% 
      mutate(!!myvar := var.bc)
  } else if (transformacion == "Quantile") {
    datos = datos %>% 
      mutate(!!myvar := var.z)
  }
}
```

```{r}
if (isTRUE(transformar)) {
  Desc(datos[[myvar]],plotit = F)
  
  (S = var(datos[[myvar]])) # varianza de la variable
  
  ggplot(datos, aes(.data[[myvar]])) + 
    geom_histogram(aes(y = after_stat(density)), bins = 10, 
                   col = 'black', fill = 'blue', alpha = .5) + 
    geom_vline(xintercept = mean(datos[[myvar]]), col = 'red') +
    geom_density(col = 'blue') +
    labs(y = 'Densidad')
}
```

# Datos espaciales

## Transformar datos en objeto espacial

Se le indica cuales son las columnas que tienen las coordenadas (X,Y) y de conocerse se le asigna el sistema de referencia de coordenadas (CRS)

```{r datos-sf}
datos_sf = st_as_sf(datos, coords = 1:2, crs = NA) %>% 
  mutate(X = st_coordinates(.)[,1], Y = st_coordinates(.)[,2]) %>% 
  select(X, Y, everything()) |> 
  mutate(.point_id = row_number())
datos_sf
```

## Calculo de distancias

Se calculan las distancias para tener una idea de la distancia maxima y por ende la distancia maxima a la cual calcular el variograma

```{r distancias}
dists = st_distance(datos_sf) %>% .[lower.tri(.)] %>% unclass()
distancias = signif(c(min(dists), mean(dists), max(dists)),6) # rango de distancias
names(distancias) = c('min', 'media', 'max') 
distancias
```

## Poligono que contiene los datos

```{r outline}
outline = st_convex_hull(st_union(datos_sf))
```

## Grilla de interpolacion

Grilla donde se quiere determinar la distribucion espacial de la variable de interes. Por lo general dentro del area de influencia de los datos.

```{r grilla-interp}
bb = st_bbox(datos_sf)
dint = max(c(bb[3]-bb[1],bb[4]-bb[2])/nrow(datos_sf))
dx = seq(bb[1],bb[3],dint) # coordenadas x
dy = seq(bb[4],bb[2],-dint) # coordenadas y
st_as_stars(matrix(0, length(dx), length(dy))) %>%
  st_set_dimensions(1, dx) %>%
  st_set_dimensions(2, dy) %>%
  st_set_dimensions(names = c("X", "Y")) %>% 
  st_set_crs(st_crs(datos_sf)) -> datosint

datosint2 = st_crop(datosint, outline)
```

## Distribucion espacial

Vista estatica y dinamica de los datos. El mapa dinamico solo se despliega en version HTML.

```{r dist-espacial}
ggplot() + 
  geom_sf(data = outline, col = 'cyan', alpha = .1, size = .75) + 
  geom_sf(data = datos_sf, aes(col = .data[[myvar]]), 
          size = 3, alpha = 0.6) + 
  scale_color_viridis_c() + 
  labs(x = x_map, y = y_map) + 
  if (!is.na(st_crs(datos_sf))) {
    coord_sf(datum = st_crs(datos_sf))
  }
```

```{r}
tm_shape(outline) + 
  tm_borders(fill_alpha = 0.1, border.col = 'cyan') +
  tm_shape(datos_sf) + 
  tm_dots(fill = myvar, size = 1, fill_alpha = 0.8, 
          fill.scale = tm_scale_continuous(values = 'brewer.spectral'), 
          fill.legend = tm_legend(title = myvar, reverse = TRUE)) + 
  tm_grid(lines = F) +
  tm_xlab(x_map) +
  tm_ylab(y_map, rotation = 90)
```

```{r dist-espacial-int, eval=knitr::is_html_output()}
mapview::mapview(outline, alpha.regions = 0, layer.name='Border', 
                 homebutton = F, legend = F, native.crs = T) + 
  mapview::mapview(datos_sf, zcol = myvar, alpha=0.1, 
                   layer.name = myvar, native.crs = T)
```

# Analisis Geoestadistico

## Variograma omnidireccional

Creacion del variograma. La funcion basica (`gstat`) realiza un buen trabajo inicial, pero se puede mejorar modificando los argumentos:

-   `cutoff`: la distancia maxima a la cual calcular el variograma
-   `width`: el lag de cada cuanto calcular el variograma

En general se recomienda que no haya pocos puntos representados en las diferentes distancias.

```{r}
formula = as.formula(paste(myvar,'~1'))
```

```{r variog-omni}
# objeto gstat para hacer geoestadistica
g = gstat(formula = formula, 
          data = datos_sf) 

dat.vgm = variogram(g) # variograma experimental

head(dat.vgm)
plot(dat.vgm)

extension = 600 # distancia maxima del variograma

dat.vgm = variogram(g, cutoff = extension) # variograma experimental hasta cierta distancia (cutoff)

plot(dat.vgm)
plot(variogram(g, cutoff = extension, width = 120))
plot(variogram(g, cutoff = extension, width = 20))

variog.omni = ggplot(dat.vgm,aes(x = dist, y = gamma)) + 
  geom_point(size = 2, col='blue', shape=21) + 
  labs(x = x_var, y = y_var) +
  geom_hline(yintercept = S, col = 'red', linetype = 2) +
  # geom_text_repel(aes(label = np), size = 3)
  ylim(0, max(dat.vgm$gamma)) +
  xlim(0, max(dat.vgm$dist))
variog.omni
```

## Mapa de la superficie del variograma

Representacion en 2D de la variable donde:

-   `width`: es el tamanho de celda
-   `cutoff`: es la extension lateral

```{r variog-map}
map.vgm <- variogram(g, width = 80, cutoff = extension, map = TRUE)

ggplot(data.frame(map.vgm), aes(x = map.dx, y = map.dy, fill = map.var1)) +
  geom_raster() + 
  scale_fill_gradientn(colours = plasma(20)) +
  labs(x = x_vmap, y = y_vmap, fill = "Semivarianza") +
  coord_quickmap()
```

## Variogramas direccionales

Variogramas en diferentes direcciones donde:

-   `alpha`: vector de direcciones sobre las cuales se va a calcular el variograma
-   `tol.hor`: tolerancia angular, usualmente 22.5

```{r variog-dir}
dat.vgm2 = variogram(g, alpha = c(0,45,90,135),
                     tol.hor = 22.5, cutoff = extension) # con direcciones y tolerancia angular

variog.dir = ggplot(dat.vgm2,aes(x = dist, y = gamma,
                    col = factor(dir.hor), shape = factor(dir.hor))) + 
  geom_point(size = 2) + 
  # geom_line() +
  labs(x = x_var, y = y_var, col = "Direccion", shape = 'Direccion') +
  geom_hline(yintercept = S, col = 'red', linetype = 2) +
  ylim(0, max(dat.vgm2$gamma)) +
  xlim(0, max(dat.vgm2$dist)) + 
  scale_color_brewer(palette = 'Dark2') +
  # facet_wrap(~dir.hor) + 
  # geom_text_repel(aes(label = np), size = 3, show.legend = F) +
  theme(legend.position = 'top')
variog.dir
```

## Modelado

### Ejemplo de modelos teoricos

Se muestran los modelos teoricos mas comunes, simulando una estructura con $C_0=0,C_1=10,a=15$, donde $a$ es el rango efectivo. Para el caso de los modelos exponencial y gaussiano el rango del modelo es $a/3$ y $a/\sqrt{3}$, respectivamente.

```{r}
show.vgms(models = c('Sph','Pen','Cir','Exp','Gau'),
          sill = 10,
          range = c(15,15,15,round(15/3,2),round(15/sqrt(3),2)),
          max = 25,n = 100,as.groups = T,plot = F) %>% 
  tibble() %>% 
  ggplot(aes(distance,semivariance,col=model)) + 
  geom_line() + 
  geom_vline(xintercept = 15,lty=2) + 
  scale_color_brewer(palette = 'Dark2') + 
  theme(legend.position = 'inside',
        legend.position.inside = c(.8,.5), 
        legend.background = element_rect('white',linewidth = .2)) + 
  labs(x = 'Distancia', y = 'Semivarianza', col = 'Modelo', 
       subtitle = 'Modelos teóricos mas comunes', 
       caption = 'Rango efectivo: 15, Meseta: 10, Pepita: 0')
```

### Valores iniciales para el variograma teorico

Es buena practica interpretar el variograma experimental y escoger un modelo apropiado, asi como valores iniciales para dicho modelo.

```{r params}
meseta = .8
mod = "Sph"
rango = 400
pep = 0.2
```

### Ajuste de variograma teorico

```{r ajuste, cache=TRUE, dependson='params'}
(vm.fit.sph = fit.variogram(dat.vgm, 
                            model = vgm(meseta, mod, rango, pep)
                            ))


# error del ajuste
(fit.rmse = sqrt(attributes(vm.fit.sph)$SSErr/(nrow(datos)))) 

# omnidireccional
plot(dat.vgm, vm.fit.sph, xlab = x_var, ylab = y_var) 

# direccionales
plot(dat.vgm2, vm.fit.sph, as.table = T, xlab = x_var, ylab = y_var) 

# proporcion pepita
vm.fit.sph[1,"psill"]/sum(vm.fit.sph[,"psill"])
```

```{r}
angle_to_dir3 <- function(theta_deg) {
  v <- c(cos(theta_deg * pi / 180), sin(theta_deg * pi / 180), 0)
  v / sqrt(sum(v^2))
}
```

```{r}
df.fit = variogramLine(vm.fit.sph, maxdist = max(dat.vgm$dist), n = 100) %>% 
  as_tibble()

variog.omni + 
  geom_line(data = df.fit, aes(dist, gamma), col = 'black', linewidth = .5, linetype='dashed', inherit.aes = F)

variog.dir + 
  geom_line(data = df.fit, aes(dist, gamma), col = 'black', linewidth = .5, linetype='dashed', inherit.aes = F)
```

### Validacion cruzada

Una vez escogido el modelo y ajustado a los datos se realiza la validacion cruzada para determinar si es aceptable. Tambien se pueden ajustar diferentes modelos y con los datos de validacion cruzada se determina el mejor. La escogencia de `nfold` depende del numero de datos, si se tienen pocos datos se recomienda usar leave-one-out (`nfold = nrow(datos_sf)`) y si se tienen muchos datos se puede usar k-fold (`nfold = 5 o 10`).

```{r}
#| eval: false
datos_sf = datos_sf |> mutate(.point_id = row_number())

datos_sf = datos_sf |> select(-c(fold,starts_with(".poi")))
```

```{r}
kfolds = 5
cluster_folds <- spatial_clustering_cv(datos_sf, v = kfolds)

fold_tbl <- map_dfr(cluster_folds$splits,
                    ~ assessment(.x) %>% select(.point_id),
                    .id = "fold")

datos_sf = datos_sf |> 
  st_join(fold_tbl, by = ".point_id") %>%
  mutate(fold = factor(fold))

datos_sf
```

```{r xval, cache=TRUE, dependson='ajuste'}
tipo.cv = 'kfold' # 'kfold', 'loo' o 'spatial'
kfolds = 5
if (tipo.cv == 'spatial') {
  nfolds = datos_sf$fold
} else if (tipo.cv == 'kfold') {
  nfolds = kfolds
} else if (tipo.cv == 'loo') {
  nfolds = nrow(datos_sf)
} else {
  stop("Tipo de validación cruzada no reconocido. Use 'kfold', 'loo' o 'spatial'.")
}

beta = ifelse(transformar & transformacion == "Quantile", 0, NULL) # 0 para KS

kcv = krige.cv(formula, 
               locations = datos_sf,
               model = vm.fit.sph,
               nfold = nfolds, 
               beta = beta)
```

El siguiente grafico muestra la distribucion espacial de los datos usados para la validacion cruzada, donde cada color representa un fold diferente. En el caso de leave-one-out cada punto es un fold diferente.

```{r}
datos_sf$fold = factor(kcv$fold)

ggplot() + 
  geom_sf(data = outline, col = 'cyan', alpha = .1, size = .75) + 
  geom_sf(data = datos_sf, aes(col = fold), 
          size = 3, alpha = 0.6) + 
  scale_color_viridis_d() + 
  labs(x = x_map, y = y_map) + 
  if (!is.na(st_crs(datos_sf))) {
    coord_sf(datum = st_crs(datos_sf))
  }
```

```{r xval-metrics, dependson='xval'}
xval.rmse = RMSE(kcv$observed, kcv$var1.pred) # RMSE - menor es mejor

xval.mape = MAPE(kcv$var1.pred, kcv$observed)

xval.mae = MAE(kcv$var1.pred, kcv$observed)

xval.msdr = mean(kcv$residual^2/kcv$var1.var) # MSDR - ~1 es mejor

xval.mod = lm(observed ~ var1.pred, as.data.frame(kcv))

xval.r2 = xval.mod %>% broom::glance() %>% pull(r.squared)

bias = mean(kcv$residual) # idealmente 0

correl = signif(CorCI(cor(kcv$observed, kcv$var1.pred), nrow(kcv)),3)

metricas = tibble(metric = c('rmse','mae','msdr','r','R2', 'bias'), 
                  estimate = c(xval.rmse,xval.mae,
                               xval.msdr,correl[1],xval.r2,bias))
metricas

CIbeta = signif(broom::tidy(xval.mod, conf.int=T)[2,c(2,6,7)],4)
CIbeta
```

```{r xval-plots, dependson='xval'}
#| layout-ncol: 2

ggplot(as.data.frame(kcv), aes(var1.pred, observed)) + 
  geom_point(col = "blue", shape = 1, size = 1.25) + 
  coord_fixed() + 
  geom_abline(slope = 1, col = "red", linewidth = 1) + 
  geom_smooth(se = F, method = 'lm', col = 'green', linewidth = 1.25) +
  labs(x = "Predecidos", y = "Observados", 
       subtitle = 'Rojo: linea 1:1, Verde: regresion')

ggplot(as.data.frame(kcv), aes(residual)) + 
  geom_histogram(bins = 15, col = 'black', fill = "blue") + 
  labs(x = "Residuales", y = "Fecuencia") + 
  geom_vline(xintercept = mean(kcv$residual), col = 'red')
```

## Interpolacion usando kriging

Si se estandariza la variable de respuesta, se utiliza Kriging Simple (KS) para la interpolación ya que este asume que se conoce la media y en este caso la media es 0. Si no se transforma la variable o se transforma con Box-Cox se usa Kriging Ordinario (KO).

```{r kriging, cache=TRUE}

varmod = vm.fit.sph # modelo escogido

if (isTRUE(transformar) & transformacion == "Box-Cox") {
  ok = krigeTg(as.formula(paste(str_remove(myvar,'.trans'),'~1')), 
               locations = datos_sf,
               newdata = datosint2, 
               model = varmod,
               lambda = lambda) 
} else if (isTRUE(transformar) & transformacion == "Quantile") {
  ok = krige(formula, 
             locations = datos_sf,
             newdata = datosint2, 
             model = varmod,
             beta = 0)
} else {
  ok = krige(formula, 
             locations = datos_sf,
             newdata = datosint2, 
             model = varmod)
}
```

## Mapas de prediccion y desviacion estandar

```{r mapas-resultados, dependson='kriging', warning=FALSE}
#| layout-ncol: 2

if (isTRUE(transformar) & transformacion == "Box-Cox") {
  pred.var = 'var1TG.pred' 
  var.var = 'var1TG.var'
} else if (isTRUE(transformar) & transformacion == "Quantile") {
  # pred.var = approx(datos[myvar], datos[myvar0], xout = ok$var1.pred)$y
  # var.var = approx(datos[myvar], datos[myvar0], xout = ok$var1.var)$y
  x_vals <- datos[[myvar]]
  y_vals <- datos[[myvar0]]
  ord <- order(x_vals, na.last = NA)

  ok$var1.pred_unq <- approx(
    x = x_vals[ord],
    y = y_vals[ord],
    xout = as.numeric(ok$var1.pred),
    rule = 2
  )$y

  ok$var1.var_unq <- approx(
    x = x_vals[ord],
    y = y_vals[ord],
    xout = as.numeric(ok$var1.var),
    rule = 2
  )$y

  pred.var = 'var1.pred_unq'
  var.var  = 'var1.var_unq'
} else {
  pred.var = 'var1.pred' 
  var.var = 'var1.var'
}
```

```{r}
ok.gg1 = ggplot() + 
  geom_stars(data = ok, aes(fill = .data[[pred.var]], x = x, y = y)) + 
  geom_contour(aes(x,y,z=.data[[pred.var]]), data.frame(ok),
               col='white',linewidth=0.1,bins = 10) + 
  scale_fill_viridis(option = 'D', direction = 1, na.value = NA) + 
  coord_sf() + 
  labs(x = x_map, y = y_map, 
       title = 'Prediccion', 
       fill = myvar0)

ok.gg2 = ggplot() + 
  geom_stars(data = ok, aes(fill = sqrt(.data[[var.var]]), x = x, y = y)) + 
  # scale_fill_gradientn(colours = brewer.pal(9,'RdPu'),
  #                      trans = 'reverse', na.value = NA) + 
  scale_fill_distiller(palette = 'RdPu', direction = 1, na.value = NA) +
  coord_sf() + 
  labs(x = x_map, y = y_map, 
       title = 'Desviacion estandar',
       fill = myvar0)

ok.gg1
ok.gg2
# gridExtra::grid.arrange(ok.gg1,ok.gg2,ncol=2)
```

```{r}
tm_shape(ok) + 
  tm_raster(pred.var, 
            col.scale = tm_scale_continuous(values = 'viridis'), 
            col.legend = tm_legend(title = myvar0, reverse = TRUE)) + 
  tm_xlab(x_map) + 
  tm_ylab(y_map, rotation = 90) + 
  tm_grid(lines = F) +
  tm_title('Prediccion')

tm_shape(ok) + 
  tm_raster(var.var, 
            col.scale = tm_scale_continuous(values = 'brewer.rd_pu'), 
            col.legend = tm_legend(title = myvar0, reverse = TRUE)) + 
  tm_xlab(x_map) + 
  tm_ylab(y_map, rotation = 90) + 
  tm_grid(lines = F) +
  tm_title('Desviacion estandar')
```

```{r}
res.df = as_tibble(ok) |> 
  select(pred = all_of(pred.var), var = all_of(var.var)) |> 
  mutate(sd = sqrt(var)) |> 
  drop_na()

summary(res.df)
```

# Interactivos

## mapview

Para poder visualizar los datos con **mapview** es necesario que estos tengan un sistema de coordenadas, sino no no va a mostrar el mapa

Para este ejemplo le asigno temporalmente el sistema de coordenadas CRTM05 (codigo EPSG 5367) para poder visualizar los datos

```{r}
ok %>% 
  select(all_of(pred.var)) %>% # capa a graficar
  st_set_crs(5367) %>% # esto no es necesario si los datos tienen un crs
  mapview::mapview(layer.name='Pred',
                   col.regions=viridis(10,option = 'D'))
```

## plotly

Para poder visualizar los datos con plotly estos tienen que estar en formato de matriz, que es lo que hace este primer bloque de codigo. Pueden cambiar la variable a visualizar cambiando el texto dentro de \[\[\]\] por el nombre de la variable respectiva.

```{r}
okmat = matrix(ok[[pred.var]],
               nrow = length(dx),
               ncol = length(dy))

x <- abs(ncol(okmat) * dint - seq_len(ncol(okmat)) * dint)
y <- seq_len(ncol(okmat)) * dint
```

### 2D

```{r warning=FALSE, eval=knitr::is_html_output()}
plot_ly(x = ~y, y = ~x, z = ~t(okmat)) %>% 
    add_contour(contours = list(showlabels = TRUE),
                line = list(smoothing = 0.85,color='white'),
                colors=viridis(10,option = 'D'), 
                colorbar=list(title=myvar0)) %>% 
    layout(xaxis = list(title=x_map),
           yaxis = list(title=y_map,scaleanchor  = "x"))
```

### 3D

```{r 3D, warning=FALSE, eval=knitr::is_html_output()}

plot_ly() %>% 
  add_surface(x = ~y, y = ~x, z = ~t(okmat), 
              colors=viridis(10,option = 'D'), 
              colorbar=list(title=myvar0)) %>% 
  layout(scene = list(xaxis=list(title=x_map), 
                      yaxis=list(title=y_map), 
                      zaxis=list(title=''),
                      aspectmode = 'manual', 
                      aspectratio = list(x = 1, y = 1, z = .5)))
```

# GeoTifs para SIG

```{r geotifs}
#| eval: false

write_stars(ok[pred.var], 'figs/krige_pred.tif')
write_stars(ok[var.var], 'figs/krige_var.tif')
```
